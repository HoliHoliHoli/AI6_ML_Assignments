{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  <center>Week 3: ASSIGNMENT 2</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use `scikit-learn` to develop a linear regression model using the same dataset in this practice and compare result.\n",
    "2. Explore the internet for an multivariant dataset and use this algorithim to train a linear regression model. Use `scikit-learn` too\n",
    "3. Rewrite the train function such that we pass `'iteration',` and `'alpha'` as arguments.\n",
    "4. What did you observe about the changing the `learning rate`?\n",
    "\n",
    "Assignment is due for submission on `03/10/2019`.\n",
    "\n",
    "Submission link will be posted on the `SLACK CHANNEL`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we will be using is a ex1data2.txt file which contains a list of bedroom sizes, number of bedrooms and their corresponding price of the house.\n",
    "\n",
    "The values on the <strong>first column</strong> contains the <strong>bedroom sizes</strong>, the values of the <strong>second column</strong> contains the <strong>number of bedrooms</strong> and values on the <strong>third column</strong> contains the corresponding <strong>price</strong> of the house in Naira.\n",
    "\n",
    "<strong>Objective</strong>: To build a multivariate linear regression model and the optimization technique to generate a model that will predict reasonable estimate of a house price when it is supplied the customers desired room size and number of rooms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "column_names = [\"size\",\"bedroom\",\"price\"]\n",
    "data = pd.read_csv('data/ex1data2.txt', names = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display 5 random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1664</td>\n",
       "      <td>2</td>\n",
       "      <td>368500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3137</td>\n",
       "      <td>3</td>\n",
       "      <td>579900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2162</td>\n",
       "      <td>4</td>\n",
       "      <td>287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>852</td>\n",
       "      <td>2</td>\n",
       "      <td>179900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1458</td>\n",
       "      <td>3</td>\n",
       "      <td>464500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3031</td>\n",
       "      <td>4</td>\n",
       "      <td>599000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1985</td>\n",
       "      <td>4</td>\n",
       "      <td>299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1427</td>\n",
       "      <td>3</td>\n",
       "      <td>198999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1767</td>\n",
       "      <td>3</td>\n",
       "      <td>252900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    size  bedroom   price\n",
       "40  1664        2  368500\n",
       "33  3137        3  579900\n",
       "39  2162        4  287000\n",
       "44   852        2  179900\n",
       "26  1458        3  464500\n",
       "19  3031        4  599000\n",
       "5   1985        4  299900\n",
       "7   1427        3  198999\n",
       "35  1437        3  249900\n",
       "20  1767        3  252900"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (47, 3), column size: 47, row size: 3\n"
     ]
    }
   ],
   "source": [
    "print('data shape: {}, column size: {}, row size: {}' \\\n",
    "      .format(data.shape, data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Problem Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beacuse we have three coefficient of `theta` `( x1, x2)`, we want to create a `97 x 2` matrix that contains the input values on the first column and second column.\n",
    "\n",
    "Notice that unlike in the last class, we did not create a third column here that contains `ones` which are coefficients for the **bias** `ie (theta0)`. This is because we would still have to normalize the input data. and it makes no sense normalizing `ones`, because we want them to remain as `ones`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input values - xs and 1s\n",
    "nrows = data.shape[0]\n",
    "ncols = data.shape[1]\n",
    "\n",
    "x = data.loc[:, ['size','bedroom']].values #converts to Numpy array\n",
    "x = x.reshape(nrows, 2)  # Alternatively x.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we want to create a row vector with a dimension of 47 x 1 for all the output values in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output variable \n",
    "y = data.loc[:, 'price'].values # convert to Numpy array\n",
    "y = y.reshape(nrows, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureNorm(x_data):\n",
    "    # save the feature data in another variable\n",
    "    x_norm = x_data.copy()\n",
    "    \n",
    "    # Create a row vector of zeros, having the same number of rows as the input feature\n",
    "    mean = np.mean(x_data, axis=0)\n",
    "    x_mean = np.mean(x_data[:, :2], axis = 0)\n",
    "    x_std = np.std(x_data[:, :2], axis = 0)\n",
    "    \n",
    "    print('Mean and std of room sizes: {}: {} respectively'.format(x_mean[0],x_std[0]))\n",
    "    print('Mean and std of bedrooms : {}: {} respectively'.format(x_mean[1],x_std[1]))\n",
    "    \n",
    "    # Using the above formula\n",
    "    x_norm = np.divide((x_data[:, :2] - x_mean), x_std)\n",
    "    \n",
    "    # Insert one vector that represents the coefficient of the bias \n",
    "    x_norm = np.insert(x_norm, 0, 1, axis=1)\n",
    "    print('A ones vector has been successfully concatenated to the input feature matrix')\n",
    "    \n",
    "    return x_norm, x_mean, x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and std of room sizes: 2000.6808510638298: 786.2026187430467 respectively\n",
      "Mean and std of bedrooms : 3.1702127659574466: 0.7528428090618781 respectively\n",
      "A ones vector has been successfully concatenated to the input feature matrix\n"
     ]
    }
   ],
   "source": [
    "x_norm, x_mean, x_std = featureNorm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the class, the process to training a linear regression model is as follow.\n",
    "\n",
    "We want to find the appropriate value of `theta` that will give us a good estimate of a city's profit if lthe city's population is supplied.\n",
    "\n",
    "To do this, \n",
    "- We want to start with a random value of `theta` to generate a hypothesis\n",
    "![title](img/model3.gif)\n",
    "\n",
    "- Then continually correct values of `theta` until the deviation of the hypothesis/prediction `h` from the ground-truth `y` is greatly reduced\n",
    "\n",
    "**Note:** In the last class, we used something like this `theta = [[0],[0],[0]]` to initialize the values of theta. Going forward, we will use the numpy function to initialize the values of theta, because we could have large number of theta values. ie `theta = np.zeros(3,1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,y, print_every):\n",
    "    #print_every = 40\n",
    "    iteration = 1000\n",
    "    \n",
    "    # For this practice are initiallizing are theta with values of zero.\n",
    "    theta = np.zeros((3,1))\n",
    "    \n",
    "    # Here, want to save our cost function or loss or square error, \n",
    "    # so that we can have an idea of how the deviation of the hypothesis from the ground thruth reduces\n",
    "    cost_function = np.zeros(iteration)\n",
    "    \n",
    "    for i in range(0, iteration):\n",
    "        # Step 1: we make a prediction using the random weights (theta) that we initialized\n",
    "        # @ is a fancy way do performing dot products\n",
    "        h = x @ theta\n",
    "        \n",
    "        # Step 2: We take a step to correct the weights (theta) to that the next predicion will be better\n",
    "        theta = update_weight(h, theta, x)\n",
    "        \n",
    "        # Step 3: We measure the deviation or error\n",
    "        cost_function[i] = cost(x, theta)\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            #print(\"Running Gradient Descent. Iteration: {} cost function: {}\".format(np.log(iteration,cost_function[i]))\n",
    "            print(\"Iteration: {}, Cost function: {} \".format(i, np.log(cost_function[i])))\n",
    "        \n",
    "    return theta, cost_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how do we check the error like we defined above?\n",
    "\n",
    "Remember the error formular (cost function)? \n",
    "![title](img/model44.gif)\n",
    "\n",
    "where:\n",
    "- `m` is the number of training example\n",
    "- `x` is the input data\n",
    "- `h` is the hypothesis\n",
    "- `y` is the prediction\n",
    "\n",
    "The equation tries to find the square error between the ground truth and the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x, theta):\n",
    "    m = x[:,0].size\n",
    "    h = x @ theta\n",
    "    return (1/2*m) * np.sum(np.square(h - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are able to get a sense of the error, how do we update how weight (theta) such that is predicts better?\n",
    "\n",
    "Like we discussed in class, gradient descent algorithim will be used for this purpose.\n",
    "\n",
    "The general formular for gradient is given below:\n",
    "![title](img/model6.gif)\n",
    "which can be differentiated to give:\n",
    "![title](img/model5.gif)\n",
    "where\n",
    "- alpha is the learning rate\n",
    "\n",
    "ie: we continually update the weight(theta) by taking steps(alpha) for the derived gradient of the error until we have sufficiently minimized theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weight(h, theta, x):\n",
    "    m = x[:,0].size\n",
    "    alpha = 0.01\n",
    "    theta = theta - alpha * (1/m * (x.T @ (h - y)))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets pass in our data and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, cost_values = train(x_norm, y, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets see our trained weights\n",
    "print('Our learned value of theta: ',theta.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize how or error reduced during the iteration. This is the power of gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost_values)\n",
    "plt.ylabel('Cost J')\n",
    "plt.xlabel('Iterations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that at the `400th iteration`, the model doesnt really change anymore. You should actually stop the iteration at that time and save cost of processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "Lets write a predict function that takes in the input features and produces an estimate price for the type of house desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, x_mean, x_std):\n",
    "    input_size = float(input(\"Input the size (square feet) of house you want: \"))\n",
    "    input_bedrooms = float(input(\"Input the number of bedrooms you desire: \"))\n",
    "    print(\"\\n Calculating -- -- -- -- -- -- -- \\n\")\n",
    "    \n",
    "    # input vector\n",
    "    input_vec = np.array([input_size, input_bedrooms])\n",
    "    \n",
    "    #print(input_vec_bias)\n",
    "    \n",
    "    # normalization of input vector\n",
    "    input_norm = np.divide((input_vec -  x_mean), x_std)\n",
    "    \n",
    "     # input vector with bias\n",
    "    input_vec_bias = np.insert(input_norm,0, 1)\n",
    "    \n",
    "    price = input_vec_bias @ theta\n",
    "    print(\"For a house of size {} sqft, with {} bedrooms. The price of estimate is N{}\".format(input_size,input_bedrooms,price[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict(theta, x_mean, x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what ius the effect of varying learning rates in the optimization of our weights?\n",
    "Below, we will plot the effect of different learning on the optimization of theta.\n",
    "\n",
    "Study the code for the next 5 mins..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose some alpha value\n",
    "alphas = [1,0,0.1,0.012]\n",
    "\n",
    "def update_weight_r(h, theta, x, alpha):\n",
    "    m = x[:,0].size\n",
    "    theta = theta - alpha * (1/m * (x.T @ (h - y)))\n",
    "    return theta\n",
    "\n",
    "def cost_r(x):\n",
    "    J = []\n",
    "    theta = [[0],[0],[0]]\n",
    "    iteration = 400\n",
    "    for i in alphas:\n",
    "        alpha = i\n",
    "        m = x[:,0].size\n",
    "        J_alpha = []\n",
    "        for i in range(iteration):\n",
    "            h = x @ theta\n",
    "            theta = update_weight_r(h, theta, x, alpha)\n",
    "            cost = (1/2*m) * np.sum(np.square(h - y))\n",
    "            J_alpha.append(cost)\n",
    "        # reset theta to zero\n",
    "        theta = [[0],[0],[0]]\n",
    "        J.append(J_alpha)\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets pass in the value of x into our function defined above \n",
    "cost_alpha = cost_r(x_norm)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(cost_alpha[0])\n",
    "plt.title('lr= 1')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(cost_alpha[1])\n",
    "plt.title('lr= 0')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(cost_alpha[2])\n",
    "plt.title('lr= 0.1')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(cost_alpha[3])\n",
    "plt.title('lr= 0.01')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Discussion/Assignment:** What did you notice in this plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Normal Equation (Analytical Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\theta = (X^TX)^{-1}X^T\\vec{y}$$\n",
    "Using this formula does not require any feature scaling, and you will get an exact solution in one calculation: there is no \\loop until convergence\" like in gradient descent.\n",
    "\n",
    "Complete the code in normaleqn.py to use the formula above to calculate $\\theta$. Remember that while you don't need to scale your features, we still need to add a column of 1's to the X matrix to have an intercept term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define the formula in a function\n",
    "def normalEqn(X,y):\n",
    "    return np.dot((np.linalg.inv(np.dot(X.T,X))),np.dot(X.T,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets pass in our input values the have not been normalized\n",
    "x_non_norm = n_data = np.insert(data.iloc[:,:2].values,0,1, axis=1)\n",
    "\n",
    "theta_analytical = normalEqn(x_non_norm, y)\n",
    "\n",
    "# Display normal equation's result\n",
    "print ('Theta computed from the normal equations:')\n",
    "print (' %s \\n' % theta_analytical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "def predict_analytical(theta):\n",
    "    input_size = float(input(\"Input the size (square feet) of house you want: \"))\n",
    "    input_bedrooms = float(input(\"Input the number of bedrooms you desire: \"))\n",
    "    print(\"\\nCalculating... ... ... ... ... ...\\n\")\n",
    "    input_vec = np.array([[1, input_size, input_bedrooms]])\n",
    "    \n",
    "    \n",
    "    price = input_vec @ theta\n",
    "    print(\"For a house of size \", input_size, \"sqft, with \", input_bedrooms, \"bedrooms, \\nThe price estimate is N\", price[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_analytical(theta_analytical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 1: \n",
    "\n",
    "### Use `scikit-learn` to develop a linear regression model using the same dataset in this practice and compare result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEPS FOR SKLEARN\n",
    "1. feature scaling = standard\n",
    "2. split datase = train_test_split\n",
    "3. train wih dataset = model.fit\n",
    "4. test with dataset = model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import libraries\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = LinearRegression()  \n",
    "model.fit(X_train, y_train) #training the alogrithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 2: \n",
    "### Explore the internet for an multivariant dataset and use this algorithim to train a linear regression model. Use `scikit-learn` too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 3: \n",
    "### Rewrite the train function such that we pass `'iteration',` and `'alpha'` as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,y, print_every, iteration = 1000, alpha = 0.01):\n",
    "    #print_every = 40\n",
    "    #iteration = 1000\n",
    "    \n",
    "    # For this practice are initiallizing are theta with values of zero.\n",
    "    theta = np.zeros((3,1))\n",
    "    \n",
    "    # Here, want to save our cost function or loss or square error, \n",
    "    # so that we can have an idea of how the deviation of the hypothesis from the ground thruth reduces\n",
    "    cost_function = np.zeros(iteration)\n",
    "    \n",
    "    for i in range(0, iteration):\n",
    "        # Step 1: we make a prediction using the random weights (theta) that we initialized\n",
    "        # @ is a fancy way do performing dot products\n",
    "        h = x @ theta\n",
    "        \n",
    "        # Step 2: We take a step to correct the weights (theta) to that the next predicion will be better\n",
    "        theta = update_weight(h, theta, x, alpha)\n",
    "        \n",
    "        # Step 3: We measure the deviation or error\n",
    "        cost_function[i] = cost(x, theta)\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            #print(\"Running Gradient Descent. Iteration: {} cost function: {}\".format(np.log(iteration,cost_function[i]))\n",
    "            print(\"Iteration: {}, Cost function: {} \".format(i, np.log(cost_function[i])))\n",
    "        \n",
    "    return theta, cost_function\n",
    "\n",
    "\n",
    "def update_weight(h, theta, x, alpha):\n",
    "    m = x[:,0].size\n",
    "    theta = theta - alpha * (1/m * (x.T @ (h - y)))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 4: \n",
    "### What did you observe about the changing the `learning rate`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is adopted from [Andrew Ng Machine Learning Course](https://www.coursera.org/learn/machine-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
